{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towing Data\n",
    "\n",
    "Minneapolis snow emergencies are declared on a given day by 6pm following heavy snowfall.  The first day of the snow emergency begins at 9pm the day of the snow emergency declaration.  Day 1 runs overnight from 9pm to 8am. Day 2 runs from 8 am to 8 pm the day after the snow emergency declaration.  Day 3 runs from 8 am to 8 pm two days after the snow emergency declaration.\n",
    "\n",
    "We consider the file `finalTOWING.csv` to expand the dataset to include information regarding snowfall amounts with the storm. To do this we download NOAA weather data on snowfall for weather stations in/near Hennepin county. \n",
    "\n",
    "For each incident of towing, we look up the date that the car was towed `date_towed` and `date_declared`, date that the snow emergency was declared.  We then find the closest weather station based on the towing latitude, longitude coordinates and return the snowfall amounts over the time frame `date_declared - one day` to `date_towed`.\n",
    "\n",
    "The NOAA data for the snowfalls has varying number of weather stations reporting, so we need to do some ETL work to get that data into a useful format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tows_df = pd.read_csv(\"finalTOWING.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ward</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>other_x</th>\n",
       "      <th>other_y</th>\n",
       "      <th>day</th>\n",
       "      <th>tow_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14248.000000</td>\n",
       "      <td>17184.000000</td>\n",
       "      <td>17184.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17184.000000</td>\n",
       "      <td>14248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.649144</td>\n",
       "      <td>44.975432</td>\n",
       "      <td>-93.267495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.068319</td>\n",
       "      <td>3.263335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.018218</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742135</td>\n",
       "      <td>1.644727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.891776</td>\n",
       "      <td>-93.460853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>44.953568</td>\n",
       "      <td>-93.289260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>44.983097</td>\n",
       "      <td>-93.267627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>44.993131</td>\n",
       "      <td>-93.246718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>45.051151</td>\n",
       "      <td>-93.202271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ward      latitude     longitude  other_x  other_y  \\\n",
       "count  14248.000000  17184.000000  17184.000000      0.0      0.0   \n",
       "mean       5.649144     44.975432    -93.267495      NaN      NaN   \n",
       "std        3.018218      0.027149      0.024902      NaN      NaN   \n",
       "min        1.000000     44.891776    -93.460853      NaN      NaN   \n",
       "25%        3.000000     44.953568    -93.289260      NaN      NaN   \n",
       "50%        5.000000     44.983097    -93.267627      NaN      NaN   \n",
       "75%        8.000000     44.993131    -93.246718      NaN      NaN   \n",
       "max       13.000000     45.051151    -93.202271      NaN      NaN   \n",
       "\n",
       "                day      tow_zone  \n",
       "count  17184.000000  14248.000000  \n",
       "mean       2.068319      3.263335  \n",
       "std        0.742135      1.644727  \n",
       "min        1.000000      1.000000  \n",
       "25%        2.000000      2.000000  \n",
       "50%        2.000000      3.000000  \n",
       "75%        3.000000      4.000000  \n",
       "max        3.000000      6.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emergency', 'date', 'address', 'ward', 'neighborhood', 'community',\n",
       "       'latitude', 'longitude', 'other_x', 'other_y', 'day', 'tow_zone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the dates to be datetime.datetime objects \n",
    "# - this allows for proper sorting and arithmetic using datetime.timedelta()\n",
    "# \n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def convert_dates(dates):\n",
    "    def try_to_parse_date (a_string):\n",
    "        try:\n",
    "            parsed = parse(a_string, fuzzy_with_tokens=True)\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse a date from `{a_string}`\")\n",
    "        else:\n",
    "            return parsed[0]\n",
    "        \n",
    "    def converter(date):\n",
    "        if isinstance(date, datetime.datetime):\n",
    "            return date\n",
    "        else:\n",
    "            return try_to_parse_date(date)\n",
    "    \n",
    "    return [converter(date) for date in dates]\n",
    "\n",
    "tows_df.insert(2, 'date_towed', convert_dates(tows_df.date))\n",
    "#converted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Armatage': Timestamp('2019-02-24 00:00:00'),\n",
       " 'Dana': Timestamp('2016-12-11 00:00:00'),\n",
       " 'Diamond Lake': Timestamp('2019-03-10 00:00:00'),\n",
       " 'Ferry': Timestamp('2016-12-17 00:00:00'),\n",
       " 'Grant': Timestamp('2015-12-29 00:00:00'),\n",
       " 'Howe': Timestamp('2018-04-15 00:00:00'),\n",
       " 'Jane': Timestamp('2017-01-11 00:00:00'),\n",
       " 'Olive': Timestamp('2018-01-15 00:00:00'),\n",
       " 'Pembina': Timestamp('2018-01-22 00:00:00'),\n",
       " 'Polk': Timestamp('2016-02-02 00:00:00'),\n",
       " 'Quincy': Timestamp('2019-01-28 00:00:00'),\n",
       " 'Upton': Timestamp('2019-02-07 00:00:00'),\n",
       " 'Westminster': Timestamp('2019-02-12 00:00:00'),\n",
       " 'Xerxes': Timestamp('2018-02-23 00:00:00'),\n",
       " 'Yale': Timestamp('2019-02-20 00:00:00'),\n",
       " 'Yardville': Timestamp('2018-02-25 00:00:00')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the date the snow emergency was declared.  This will be the smallest value of date_towed for any day 1 towing.\n",
    "\n",
    "declaration_dict = tows_df[tows_df.day == 1].groupby('emergency')['date_towed'].min().to_dict()\n",
    "declaration_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency</th>\n",
       "      <th>date_declared</th>\n",
       "      <th>date</th>\n",
       "      <th>date_towed</th>\n",
       "      <th>address</th>\n",
       "      <th>ward</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>community</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>other_x</th>\n",
       "      <th>other_y</th>\n",
       "      <th>day</th>\n",
       "      <th>tow_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2101 LYNDALE AVE N ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.000250</td>\n",
       "      <td>-93.287993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2101 LYNDALE AVE N ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.000250</td>\n",
       "      <td>-93.287993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2806 EMERSON AVE S,Minneapolis,MN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Lowry Hill East</td>\n",
       "      <td>Calhoun Isle</td>\n",
       "      <td>44.951599</td>\n",
       "      <td>-93.294638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2901 Lyndale Ave n ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.009708</td>\n",
       "      <td>-93.288395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2800 Emerson Avenue South,Minneapolis,MN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Lowry Hill East</td>\n",
       "      <td>Calhoun Isle</td>\n",
       "      <td>44.951578</td>\n",
       "      <td>-93.294725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emergency date_declared     date date_towed  \\\n",
       "0  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "1  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "2  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "3  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "4  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "\n",
       "                                    address  ward     neighborhood  \\\n",
       "0        2101 LYNDALE AVE N ,Minneapolis,MN   5.0        Hawthorne   \n",
       "1        2101 LYNDALE AVE N ,Minneapolis,MN   5.0        Hawthorne   \n",
       "2         2806 EMERSON AVE S,Minneapolis,MN  10.0  Lowry Hill East   \n",
       "3        2901 Lyndale Ave n ,Minneapolis,MN   5.0        Hawthorne   \n",
       "4  2800 Emerson Avenue South,Minneapolis,MN  10.0  Lowry Hill East   \n",
       "\n",
       "      community   latitude  longitude  other_x  other_y  day  tow_zone  \n",
       "0    Near North  45.000250 -93.287993      NaN      NaN    1       1.0  \n",
       "1    Near North  45.000250 -93.287993      NaN      NaN    1       1.0  \n",
       "2  Calhoun Isle  44.951599 -93.294638      NaN      NaN    1       3.0  \n",
       "3    Near North  45.009708 -93.288395      NaN      NaN    1       1.0  \n",
       "4  Calhoun Isle  44.951578 -93.294725      NaN      NaN    1       3.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df.insert(1, 'date_declared', tows_df['emergency'].map(declaration_dict))\n",
    "tows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(tows_df.date_towed.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are looking at days prior to the snow emergency declaration and the NOAA weather station data is monthly,\n",
    "# we need to enlarge the number of dates that are going to be pulled from the NOAA site in case there are monthly cross-overs\n",
    "# The following function creates this list of enlarged dates.\n",
    "\n",
    "def enlarge_dates_list(tow_dates):\n",
    "    # a helper function to push dates into a list.\n",
    "    def check_date_in_list(date, my_list):\n",
    "        if date not in my_list:\n",
    "            my_list.append(date)\n",
    "            \n",
    "    enlarged_dates = []\n",
    "    for date in tow_dates:\n",
    "        check_date_in_list(date, enlarged_dates)\n",
    "        check_date_in_list(date - datetime.timedelta(days=1), enlarged_dates)\n",
    "        check_date_in_list(date - datetime.timedelta(days=2), enlarged_dates)\n",
    "        check_date_in_list(date - datetime.timedelta(days=3), enlarged_dates)\n",
    "        \n",
    "    return enlarged_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlarged_dates = enlarge_dates_list(tows_df.date_towed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enlarged_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201512.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201601.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201602.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201612.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201701.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201801.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201802.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201804.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201901.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201902.json',\n",
       " 'https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201903.json']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make API endpoint names from the above information\n",
    "# https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-201903.json\n",
    "# Use a set generator to drop duplicates by default\n",
    "\n",
    "def create_api_endpoints(dates):\n",
    "    # three helper functions\n",
    "    def zero_pad_month(month):\n",
    "        return str(month).zfill(2)\n",
    "    \n",
    "    def combine_month_year(months, year):\n",
    "        month_years = zip(months, years)\n",
    "        return {str(year) + zero_pad_month(month) for (month, year) in month_years}\n",
    "\n",
    "    def make_endpoints(endpoint_prefix, endpoint_suffix, changing_term):\n",
    "        return [endpoint_prefix + term + endpoint_suffix for term in changing_term]\n",
    "\n",
    "    months = [day.month for day in dates]\n",
    "    years = [day.year for day in dates]\n",
    "    unique_month_years = combine_month_year(months, years)\n",
    "    api_endpoints = (make_endpoints(\"https://www.ncdc.noaa.gov/snow-and-ice/daily-snow/MN-snowfall-\",\n",
    "                                        \".json\",\n",
    "                                        unique_month_years))\n",
    "    \n",
    "    return unique_month_years, api_endpoints\n",
    "\n",
    "unique_month_years, api_endpoints = create_api_endpoints(enlarged_dates)\n",
    "sorted(api_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now get the snowfall data and build it up as a json\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_snowfall_jsons(unique_month_years, api_endpoints):\n",
    "    \n",
    "    all_snowfalls = {}\n",
    "    snowfalls = []\n",
    "    for (monthyear, endpoint) in zip(unique_month_years, api_endpoints):\n",
    "        snowfall = {}\n",
    "        response = requests.get(endpoint)\n",
    "        print(monthyear, response)\n",
    "        snowfall[\"date\"] = monthyear\n",
    "        if response:\n",
    "            snowfall[\"data\"] = response.json()\n",
    "        else:\n",
    "            snowfall[\"data\"] = False\n",
    "        snowfalls.append(snowfall)\n",
    "        \n",
    "    all_snowfalls[\"snowfalls\"] = snowfalls\n",
    "    return all_snowfalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201701 <Response [200]>\n",
      "201901 <Response [200]>\n",
      "201802 <Response [200]>\n",
      "201612 <Response [200]>\n",
      "201801 <Response [200]>\n",
      "201902 <Response [200]>\n",
      "201601 <Response [200]>\n",
      "201804 <Response [200]>\n",
      "201512 <Response [404]>\n",
      "201903 <Response [200]>\n",
      "201602 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "snowfalls = get_snowfall_jsons(unique_month_years, api_endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 11\n"
     ]
    }
   ],
   "source": [
    "# How many unique months of data do we have?  Note that 201512 is unavailable:  Response [404]\n",
    "print(len(snowfalls), len(snowfalls['snowfalls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To avoid making API calls again, we can save our data so far:\n",
    "\n",
    "with open('snowfalls.json', 'w') as outfile:  \n",
    "    json.dump(snowfalls, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the lines below to pick up the analysis from here and start again\n",
    "with open('snowfalls.json', 'r') as infile:\n",
    "    reloaded_snowfalls = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[311, 358, 358, 343, 354, 373, 349, 406, 0, 371, 336]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gets all of the weather stations for the first snowfall:\n",
    "# snowfalls['snowfalls'][0]['data']['data'].keys()\n",
    "\n",
    "# How many weather stations per month/year combinations?\n",
    "# We will see that there are varying number of weather stations available.\n",
    "\n",
    "def count_weather_stations ():\n",
    "    station_count = []\n",
    "    \n",
    "    for i in range(len(snowfalls['snowfalls'])):\n",
    "        if snowfalls['snowfalls'][i]['data']:\n",
    "            station_count.append(len(snowfalls['snowfalls'][i]['data']['data'].keys()))\n",
    "        else:\n",
    "            station_count.append(0)\n",
    "    return station_count\n",
    "\n",
    "count_weather_stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n"
     ]
    }
   ],
   "source": [
    "# Determine the largest set of MN weather stations:\n",
    "\n",
    "def get_mn_weather_stations(jsobject):\n",
    "    # Loop over all snowstorms and find all of the unique weather stations\n",
    "    snowfall_list = jsobject['snowfalls']\n",
    "    stations = []\n",
    "    \n",
    "    for snowfall in snowfall_list:\n",
    "        # print(snowfall['date'])\n",
    "        # recall one snowfall has no data available from the server:\n",
    "        if (snowfall['data']):\n",
    "            stations.append( list(snowfall['data']['data'].keys()) )\n",
    "            \n",
    "    flat_list = [item for sublist in stations for item in sublist]\n",
    "    \n",
    "    return list(set(flat_list))\n",
    "\n",
    "mn_stations = get_mn_weather_stations(snowfalls)\n",
    "print(len(mn_stations)) # 548 of these\n",
    "# mn_stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a data frame of mn weather stations\n",
    "def make_mn_stations_df (stations, jsobject):\n",
    "    \n",
    "    snowfall_list = jsobject['snowfalls']\n",
    "    \n",
    "    #new_stations = []\n",
    "    already_found_stations = []\n",
    "    lat = []\n",
    "    lon = []\n",
    "    county = []\n",
    "    name = []\n",
    "    \n",
    "    for snowfall in snowfall_list:\n",
    "        \n",
    "        if (snowfall['data']):\n",
    "            # see if station is in the snowfall:\n",
    "            for station in stations:\n",
    "                if station in snowfall['data']['data'].keys():\n",
    "                    # get station data\n",
    "                    if station not in already_found_stations:\n",
    "                        already_found_stations.append(station)\n",
    "                        lat.append(float(snowfall['data']['data'][station]['lat']))\n",
    "                        lon.append(float(snowfall['data']['data'][station]['lon']))\n",
    "                        county.append(snowfall['data']['data'][station]['county'])\n",
    "                        name.append(snowfall['data']['data'][station]['station_name'])\n",
    "    \n",
    "    # make a dataframe of stations from the lists:\n",
    "    data_dict = {'Station': already_found_stations,\\\n",
    "                'Name': name,\\\n",
    "                'County': county,\\\n",
    "                'lat': lat, 'lon': lon}\n",
    "    \n",
    "    stations_df = pd.DataFrame(data_dict)\n",
    "    return stations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_stations_df = make_mn_stations_df(mn_stations, snowfalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Name</th>\n",
       "      <th>County</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USC00214994</td>\n",
       "      <td>MADISON WWTP</td>\n",
       "      <td>LAC QUI PARLE</td>\n",
       "      <td>45.00</td>\n",
       "      <td>-96.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US1MNBW0008</td>\n",
       "      <td>COMFREY 6.5 ENE</td>\n",
       "      <td>BROWN</td>\n",
       "      <td>44.15</td>\n",
       "      <td>-94.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00216211</td>\n",
       "      <td>ORR 3E</td>\n",
       "      <td>ST. LOUIS</td>\n",
       "      <td>48.05</td>\n",
       "      <td>-92.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US1MNWG0033</td>\n",
       "      <td>COTTAGE GROVE 1.6 NNW</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>44.84</td>\n",
       "      <td>-92.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00210252</td>\n",
       "      <td>ARGYLE</td>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>48.33</td>\n",
       "      <td>-96.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Station                   Name         County    lat    lon\n",
       "0  USC00214994           MADISON WWTP  LAC QUI PARLE  45.00 -96.17\n",
       "1  US1MNBW0008        COMFREY 6.5 ENE          BROWN  44.15 -94.79\n",
       "2  USC00216211                 ORR 3E      ST. LOUIS  48.05 -92.76\n",
       "3  US1MNWG0033  COTTAGE GROVE 1.6 NNW     WASHINGTON  44.84 -92.94\n",
       "4  USC00210252                 ARGYLE       MARSHALL  48.33 -96.83"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "County\n",
       "HENNEPIN    61\n",
       "Name: Station, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many stations in Hennepin county\n",
    "mn_stations_df[mn_stations_df['County'] == 'HENNEPIN'].groupby('County')['Station'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_stations_df.to_csv('mn_weather_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the closest weather station to a towing incident based on lat, lon coordinates given:\n",
    "## https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula\n",
    "from math import cos, asin, sqrt\n",
    "import numbers\n",
    "\n",
    "# This is distance on a globe - not Euclidean\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Distance on a globe -returns values in kilometers\n",
    "    p = 0.017453292519943295\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(a))\n",
    "\n",
    "def closest_weather_station (weather_station_df, point):\n",
    "\n",
    "    # local function\n",
    "    def distance_to_point(lat, lon):\n",
    "        return haversine_distance(lat, lon, point[0], point[1])\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    for row in weather_station_df.itertuples():\n",
    "        #print(row)\n",
    "        # I check if a number and convert to floats to take care of missing info\n",
    "        if isinstance(float(row.lat), numbers.Number):\n",
    "            distances.append(distance_to_point(float(row.lat), float(row.lon)))\n",
    "        else:\n",
    "            distances.append(np.inf)\n",
    "        \n",
    "    val, idx = min((val, idx) for (idx, val) in enumerate(distances))\n",
    "    \n",
    "    return weather_station_df.iloc[idx,:]['Station']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US1MNMK0008\n"
     ]
    }
   ],
   "source": [
    "# Try it out with a weather station in the data frame\n",
    "print(closest_weather_station(mn_stations_df, [45.05, -94.26]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US1MNHN0009'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it out with the first towing in the tows_df:\n",
    "closest_weather_station(mn_stations_df, [45.00025,-93.287993])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Name</th>\n",
       "      <th>County</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>US1MNHN0009</td>\n",
       "      <td>MINNEAPOLIS 3.0 NNW</td>\n",
       "      <td>HENNEPIN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-93.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Station                 Name    County   lat    lon\n",
       "238  US1MNHN0009  MINNEAPOLIS 3.0 NNW  HENNEPIN  45.0 -93.29"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn_stations_df[mn_stations_df['Station'] == 'US1MNHN0009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09983300908083753\n"
     ]
    }
   ],
   "source": [
    "from geopy import distance\n",
    "tow1 = (45.00025,-93.287993)\n",
    "station1 = (45.0, -93.29)\n",
    "print(distance.distance(tow1, station1).miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall the structure of the snowfall json file:\n",
    "def find_snowfall_by_date(snowfall_json, date, station):\n",
    "    # Find the month, year combination used in the snowfall_json:\n",
    "    # the format in the JSON file is YYYYMM\n",
    "    day = date.day\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    key = str(year) + str(month).zfill(2)\n",
    "    \n",
    "    #print(key)\n",
    "    \n",
    "    for snowfall in snowfall_json['snowfalls']:\n",
    "        if snowfall['data']:\n",
    "            if snowfall['date'] == key:\n",
    "                # Found the correct date ---\n",
    "                # print(snowfall['date'])\n",
    "                #print(snowfall['data'].keys())\n",
    "                station_data = snowfall['data']['data']\n",
    "                # Now check if the station is in the snowfall data:\n",
    "                if station in station_data.keys():\n",
    "                    ## Found the correct station --\n",
    "                    # print(snowfall['data']['data'][station].keys())\n",
    "                    snowfall = snowfall['data']['data'][station]['values'][str(day)]\n",
    "                    if snowfall == 'M':\n",
    "                        amount = 0.0\n",
    "                    elif snowfall == 'T':\n",
    "                        amount = 0.1\n",
    "                    else:\n",
    "                        amount = float(snowfall)\n",
    "                else:\n",
    "                    #print(\"No station information\")\n",
    "                    amount = 0.0\n",
    "                    \n",
    "                return amount \n",
    "        else:\n",
    "            amount = -1.0 # No data for the snowfall is available\n",
    "    \n",
    "    return amount\n",
    "        \n",
    "find_snowfall_by_date(snowfalls, datetime.datetime(2019, 2, 24, 0, 0), 'US1MNHN0009')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('US1MNHN0009', 1.8, 0.0, 0.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each tow in the dataset:  expand the dataset as follows:\n",
    "\n",
    "def get_prior_days_snowfall(stations_df, snowfall_json, date, lat, lon):\n",
    "    # Find the closest weather station\n",
    "    station = closest_weather_station(stations_df, [lat, lon])\n",
    "    \n",
    "    #print(station)\n",
    "    day0_snow = find_snowfall_by_date(snowfall_json, date, station)\n",
    "    day1_snow = find_snowfall_by_date(snowfall_json, date-datetime.timedelta(days=1), station)\n",
    "    day2_snow = find_snowfall_by_date(snowfall_json, date-datetime.timedelta(days=2), station)\n",
    "    \n",
    "    return station, day0_snow, day1_snow, day2_snow\n",
    "\n",
    "# a test case - 02/24/2019 09:20pm\t02/24/2019\t09:20pm\tSnow Emergency\t2101 LYNDALE AVE N ,Minneapolis,MN\t45.00025\t-93.287993\n",
    "\n",
    "get_prior_days_snowfall(mn_stations_df, snowfalls, datetime.datetime(2019, 2, 24, 0, 0), 45.00025, -93.287993)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('US1MNHN0009', 1.8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cumulative_snowfall(stations_df, snowfall_json, date_declared, date_towed, lat, lon):\n",
    "    # Find the closest weather station\n",
    "    station = closest_weather_station(stations_df, [lat, lon])\n",
    "    \n",
    "    start = date_declared - datetime.timedelta(days=2) # Two days before snow emergency\n",
    "    end = date_towed\n",
    "    dates_range = [start + datetime.timedelta(days=x) for x in range(0, 1 + (end-start).days)]\n",
    "    # print(dates_range)\n",
    "    \n",
    "    cumulative_snow = 0\n",
    "    for date in dates_range:\n",
    "        cumulative_snow = cumulative_snow + find_snowfall_by_date(snowfall_json, date, station)\n",
    "        \n",
    "    return station, cumulative_snow\n",
    "\n",
    "get_cumulative_snowfall(mn_stations_df, snowfalls, datetime.datetime(2019,2,24,0,0), datetime.datetime(2019,2,24,0,0), 45.00025, -93.287993)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_station_and_snowfall_data (tows_df, stations_df, snowfall_json):\n",
    "    \n",
    "    station = []\n",
    "    snow = []\n",
    "    \n",
    "    for row in tows_df.itertuples():\n",
    "        date_declared = row.date_declared\n",
    "        date_towed = row.date_towed\n",
    "        tow_lat = row.latitude\n",
    "        tow_lon = row.longitude\n",
    "        if ( isinstance(tow_lat, numbers.Number) and isinstance(tow_lon, numbers.Number) ):\n",
    "            stat, snow_total = get_cumulative_snowfall(stations_df, snowfall_json, date_declared, date_towed, tow_lat, tow_lon)\n",
    "        else:\n",
    "            stat, snow_total = '', -1\n",
    "        station.append(stat)\n",
    "        snow.append(snow_total)\n",
    "\n",
    "    expanded_tows = tows_df.copy()\n",
    "    expanded_tows['Station'] = station\n",
    "    expanded_tows['Snowfall'] = snow\n",
    "    \n",
    "    return expanded_tows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tows_df = add_station_and_snowfall_data(tows_df, mn_stations_df, snowfalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emergency', 'date_declared', 'date', 'date_towed', 'address', 'ward',\n",
       "       'neighborhood', 'community', 'latitude', 'longitude', 'other_x',\n",
       "       'other_y', 'day', 'tow_zone', 'Station', 'Snowfall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tows_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_declared</th>\n",
       "      <th>emergency</th>\n",
       "      <th>date_towed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2015-12-29</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Grant</th>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-02-02</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Polk</th>\n",
       "      <th>2016-02-02</th>\n",
       "      <td>0.006040</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-03</th>\n",
       "      <td>6.361688</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-04</th>\n",
       "      <td>7.402820</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-12-11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Dana</th>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>2.146018</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>3.915953</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>4.419787</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-12-17</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ferry</th>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>1.804000</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>3.085566</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>2.971198</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-01-11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Jane</th>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>0.762222</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>1.595025</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>1.409888</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-01-15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Olive</th>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>1.601923</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>1.561860</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>1.674272</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-01-22</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Pembina</th>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>0.017647</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>7.030690</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24</th>\n",
       "      <td>7.170382</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-02-23</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Xerxes</th>\n",
       "      <th>2018-02-23</th>\n",
       "      <td>4.498485</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24</th>\n",
       "      <td>3.929619</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-25</th>\n",
       "      <td>8.651070</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-02-25</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yardville</th>\n",
       "      <th>2018-02-25</th>\n",
       "      <td>7.912621</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>7.885490</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>8.606087</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-04-15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Howe</th>\n",
       "      <th>2018-04-15</th>\n",
       "      <td>10.273418</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>11.781070</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>11.948387</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019-01-28</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Quincy</th>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>1.729703</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>1.781977</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-07</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upton</th>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>2.589062</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>8.112556</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09</th>\n",
       "      <td>8.089153</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-12</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Westminster</th>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>4.134783</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>6.989934</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>6.107447</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-20</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yale</th>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>0.998684</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>6.039417</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>6.201320</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-24</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Armatage</th>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>1.650000</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>2.818318</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>2.293994</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-03-10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diamond Lake</th>\n",
       "      <th>2019-03-10</th>\n",
       "      <td>4.080000</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>4.453689</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>4.883290</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean  count\n",
       "date_declared emergency    date_towed                  \n",
       "2015-12-29    Grant        2015-12-29  -3.000000    171\n",
       "                           2015-12-30  -4.000000    912\n",
       "                           2015-12-31  -5.000000    473\n",
       "2016-02-02    Polk         2016-02-02   0.006040    149\n",
       "                           2016-02-03   6.361688    770\n",
       "                           2016-02-04   7.402820    461\n",
       "2016-12-11    Dana         2016-12-11   2.146018    113\n",
       "                           2016-12-12   3.915953    771\n",
       "                           2016-12-13   4.419787    470\n",
       "2016-12-17    Ferry        2016-12-17   1.804000    125\n",
       "                           2016-12-18   3.085566    769\n",
       "                           2016-12-19   2.971198    434\n",
       "2017-01-11    Jane         2017-01-11   0.762222     90\n",
       "                           2017-01-12   1.595025    804\n",
       "                           2017-01-13   1.409888    536\n",
       "2018-01-15    Olive        2018-01-15   1.601923    104\n",
       "                           2018-01-16   1.561860    645\n",
       "                           2018-01-17   1.674272    412\n",
       "2018-01-22    Pembina      2018-01-22   0.017647     68\n",
       "                           2018-01-23   7.030690    580\n",
       "                           2018-01-24   7.170382    314\n",
       "2018-02-23    Xerxes       2018-02-23   4.498485    132\n",
       "                           2018-02-24   3.929619    709\n",
       "                           2018-02-25   8.651070    374\n",
       "2018-02-25    Yardville    2018-02-25   7.912621    103\n",
       "                           2018-02-26   7.885490    510\n",
       "                           2018-02-27   8.606087    115\n",
       "2018-04-15    Howe         2018-04-15  10.273418     79\n",
       "                           2018-04-16  11.781070    486\n",
       "                           2018-04-17  11.948387    279\n",
       "2019-01-28    Quincy       2019-01-28   1.729703    101\n",
       "                           2019-01-29   1.781977    516\n",
       "2019-02-07    Upton        2019-02-07   2.589062     64\n",
       "                           2019-02-08   8.112556    446\n",
       "                           2019-02-09   8.089153    295\n",
       "2019-02-12    Westminster  2019-02-12   4.134783     92\n",
       "                           2019-02-13   6.989934    606\n",
       "                           2019-02-14   6.107447    282\n",
       "2019-02-20    Yale         2019-02-20   0.998684     76\n",
       "                           2019-02-21   6.039417    515\n",
       "                           2019-02-22   6.201320    303\n",
       "2019-02-24    Armatage     2019-02-24   1.650000     80\n",
       "                           2019-02-25   2.818318    535\n",
       "                           2019-02-26   2.293994    333\n",
       "2019-03-10    Diamond Lake 2019-03-10   4.080000    105\n",
       "                           2019-03-11   4.453689    488\n",
       "                           2019-03-12   4.883290    389"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_snowfall = expanded_tows_df.groupby(['date_declared', 'emergency', 'date_towed'])['Snowfall']\n",
    "grouped_snowfall.agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from queue import PriorityQueue \n",
    "\n",
    "from geopy import distance\n",
    "#tow1 = (45.00025,-93.287993)\n",
    "#station1 = (45.0, -93.29)\n",
    "#print(distance.distance(tow1, station1).miles)\n",
    "# derived from the code given in \n",
    "# https://www.geeksforgeeks.org/find-k-closest-numbers-in-an-unsorted-array/\n",
    "\n",
    "def get_K_closest_weather_stations(stations_df, k, lat, lon): \n",
    "  \n",
    "    n = len(stations_df)\n",
    "    \n",
    "    # Make a max heap of difference with  \n",
    "    # first k elements.  \n",
    "    pq = PriorityQueue() \n",
    "    for i in range(k):\n",
    "        lat_i = stations_df.loc[i, 'lat']\n",
    "        lon_i = stations_df.loc[i, 'lon']\n",
    "        dist = distance.distance((lat_i, lon_i), (lat, lon)).miles\n",
    "        \n",
    "        pq.put( (-dist, i) ) \n",
    "  \n",
    "    # Now process remaining elements \n",
    "    for i in range(k,n):\n",
    "        lat_i = stations_df.loc[i, 'lat']\n",
    "        lon_i = stations_df.loc[i, 'lon']\n",
    "        dist = distance.distance((lat_i, lon_i), (lat, lon)).miles\n",
    "        \n",
    "        p,pi = pq.get() \n",
    "        curr = -p \n",
    "  \n",
    "        # If dist with current  \n",
    "        # element is more than root,  \n",
    "        # then put it back.  \n",
    "        if dist>curr: \n",
    "            pq.put((-curr,pi)) \n",
    "            continue\n",
    "        else: \n",
    "            # Else remove root and insert \n",
    "            pq.put((-dist,i))\n",
    " \n",
    "    closest = []\n",
    "    while(not pq.empty()): \n",
    "        p,q = pq.get()\n",
    "        closest.append(stations_df.loc[q, 'Station'])\n",
    "    \n",
    "    return closest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US1MNHN0065', 'USC00214884', 'US1MNHN0009']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_K_closest_weather_stations(mn_stations_df, 3, 45.00025, -93.287993 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['US1MNHN0181', 'US1MNHN0128', 'US1MNHN0065', 'USC00214884', 'US1MNHN0009'],\n",
       " 5,\n",
       " 3.6)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_average_cumulative_snowfall(stations_df, snowfall_json, date_declared, date_towed, k, lat, lon):\n",
    "    # Find the K closest weather stations\n",
    "    stations = get_K_closest_weather_stations(stations_df, k, lat, lon)\n",
    "    \n",
    "    start = date_declared - datetime.timedelta(days=1) # One day before snow emergency\n",
    "    end = date_towed\n",
    "    dates_range = [start + datetime.timedelta(days=x) for x in range(0, 1 + (end-start).days)]\n",
    "    # print(dates_range)\n",
    "    \n",
    "    num_stations = 0\n",
    "    cumulative_snow = 0\n",
    "    for station in stations:\n",
    "        station_cumulative_snow = 0\n",
    "        for date in dates_range:\n",
    "            station_cumulative_snow = station_cumulative_snow + find_snowfall_by_date(snowfall_json, date, station)\n",
    "        if not math.isclose(station_cumulative_snow, 0.0):\n",
    "            # We have a station reporting \n",
    "            # We only take an average with reporting stations\n",
    "            num_stations = num_stations + 1\n",
    "            cumulative_snow = cumulative_snow + station_cumulative_snow\n",
    "    \n",
    "    if num_stations == 0:\n",
    "        return stations, num_stations, cumulative_snow\n",
    "    else:\n",
    "        return stations, num_stations, cumulative_snow / num_stations\n",
    "\n",
    "get_average_cumulative_snowfall(mn_stations_df, snowfalls, datetime.datetime(2019,2,24,0,0), datetime.datetime(2019,2,24,0,0), 5, 45.00025, -93.287993)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_five_stations_and_snowfall_data (tows_df, stations_df, snowfall_json):\n",
    "    \n",
    "    station1 = []\n",
    "    station2 = []\n",
    "    station3 = []\n",
    "    station4 = []\n",
    "    station5 = []\n",
    "    n_reporting = []\n",
    "    snow = []\n",
    "    \n",
    "    for row in tows_df.itertuples():\n",
    "        date_declared = row.date_declared\n",
    "        date_towed = row.date_towed\n",
    "        tow_lat = row.latitude\n",
    "        tow_lon = row.longitude\n",
    "        if ( isinstance(tow_lat, numbers.Number) and isinstance(tow_lon, numbers.Number) ):\n",
    "            stats, reporting, snow_total = get_average_cumulative_snowfall(stations_df, snowfall_json, date_declared, date_towed, 5, tow_lat, tow_lon)\n",
    "        else:\n",
    "            stats, reporting, snow_total = '', -1, -1\n",
    "        station1.append(stats[0])\n",
    "        station2.append(stats[1])\n",
    "        station3.append(stats[2])\n",
    "        station4.append(stats[3])\n",
    "        station5.append(stats[4])\n",
    "        n_reporting.append(reporting)\n",
    "        snow.append(snow_total)\n",
    "\n",
    "    expanded_tows = tows_df.copy()\n",
    "    expanded_tows['Station1'] = station1\n",
    "    expanded_tows['Station2'] = station2\n",
    "    expanded_tows['Station3'] = station3\n",
    "    expanded_tows['Station4'] = station4\n",
    "    expanded_tows['Station5'] = station5\n",
    "    expanded_tows['Num Reporting'] = n_reporting\n",
    "    expanded_tows['Snowfall'] = snow\n",
    "    \n",
    "    return expanded_tows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tows_df = add_five_stations_and_snowfall_data(tows_df, mn_stations_df, snowfalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency</th>\n",
       "      <th>date_declared</th>\n",
       "      <th>date</th>\n",
       "      <th>date_towed</th>\n",
       "      <th>address</th>\n",
       "      <th>ward</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>community</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>other_y</th>\n",
       "      <th>day</th>\n",
       "      <th>tow_zone</th>\n",
       "      <th>Station1</th>\n",
       "      <th>Station2</th>\n",
       "      <th>Station3</th>\n",
       "      <th>Station4</th>\n",
       "      <th>Station5</th>\n",
       "      <th>Num Reporting</th>\n",
       "      <th>Snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2101 LYNDALE AVE N ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.000250</td>\n",
       "      <td>-93.287993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US1MNHN0181</td>\n",
       "      <td>US1MNHN0128</td>\n",
       "      <td>US1MNHN0065</td>\n",
       "      <td>USC00214884</td>\n",
       "      <td>US1MNHN0009</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2101 LYNDALE AVE N ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.000250</td>\n",
       "      <td>-93.287993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US1MNHN0181</td>\n",
       "      <td>US1MNHN0128</td>\n",
       "      <td>US1MNHN0065</td>\n",
       "      <td>USC00214884</td>\n",
       "      <td>US1MNHN0009</td>\n",
       "      <td>5</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2806 EMERSON AVE S,Minneapolis,MN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Lowry Hill East</td>\n",
       "      <td>Calhoun Isle</td>\n",
       "      <td>44.951599</td>\n",
       "      <td>-93.294638</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US1MNHN0028</td>\n",
       "      <td>US1MNHN0152</td>\n",
       "      <td>US1MNHN0181</td>\n",
       "      <td>US1MNHN0022</td>\n",
       "      <td>US1MNHN0174</td>\n",
       "      <td>3</td>\n",
       "      <td>4.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2901 Lyndale Ave n ,Minneapolis,MN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Near North</td>\n",
       "      <td>45.009708</td>\n",
       "      <td>-93.288395</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>USC00214884</td>\n",
       "      <td>US1MNHN0065</td>\n",
       "      <td>US1MNHN0108</td>\n",
       "      <td>US1MNHN0128</td>\n",
       "      <td>US1MNHN0009</td>\n",
       "      <td>4</td>\n",
       "      <td>3.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armatage</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2/24/19</td>\n",
       "      <td>2019-02-24</td>\n",
       "      <td>2800 Emerson Avenue South,Minneapolis,MN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Lowry Hill East</td>\n",
       "      <td>Calhoun Isle</td>\n",
       "      <td>44.951578</td>\n",
       "      <td>-93.294725</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US1MNHN0028</td>\n",
       "      <td>US1MNHN0152</td>\n",
       "      <td>US1MNHN0181</td>\n",
       "      <td>US1MNHN0022</td>\n",
       "      <td>US1MNHN0174</td>\n",
       "      <td>3</td>\n",
       "      <td>4.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  emergency date_declared     date date_towed  \\\n",
       "0  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "1  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "2  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "3  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "4  Armatage    2019-02-24  2/24/19 2019-02-24   \n",
       "\n",
       "                                    address  ward     neighborhood  \\\n",
       "0        2101 LYNDALE AVE N ,Minneapolis,MN   5.0        Hawthorne   \n",
       "1        2101 LYNDALE AVE N ,Minneapolis,MN   5.0        Hawthorne   \n",
       "2         2806 EMERSON AVE S,Minneapolis,MN  10.0  Lowry Hill East   \n",
       "3        2901 Lyndale Ave n ,Minneapolis,MN   5.0        Hawthorne   \n",
       "4  2800 Emerson Avenue South,Minneapolis,MN  10.0  Lowry Hill East   \n",
       "\n",
       "      community   latitude  longitude    ...     other_y  day  tow_zone  \\\n",
       "0    Near North  45.000250 -93.287993    ...         NaN    1       1.0   \n",
       "1    Near North  45.000250 -93.287993    ...         NaN    1       1.0   \n",
       "2  Calhoun Isle  44.951599 -93.294638    ...         NaN    1       3.0   \n",
       "3    Near North  45.009708 -93.288395    ...         NaN    1       1.0   \n",
       "4  Calhoun Isle  44.951578 -93.294725    ...         NaN    1       3.0   \n",
       "\n",
       "      Station1     Station2     Station3     Station4     Station5  \\\n",
       "0  US1MNHN0181  US1MNHN0128  US1MNHN0065  USC00214884  US1MNHN0009   \n",
       "1  US1MNHN0181  US1MNHN0128  US1MNHN0065  USC00214884  US1MNHN0009   \n",
       "2  US1MNHN0028  US1MNHN0152  US1MNHN0181  US1MNHN0022  US1MNHN0174   \n",
       "3  USC00214884  US1MNHN0065  US1MNHN0108  US1MNHN0128  US1MNHN0009   \n",
       "4  US1MNHN0028  US1MNHN0152  US1MNHN0181  US1MNHN0022  US1MNHN0174   \n",
       "\n",
       "  Num Reporting  Snowfall  \n",
       "0             5  3.600000  \n",
       "1             5  3.600000  \n",
       "2             3  4.233333  \n",
       "3             4  3.350000  \n",
       "4             3  4.233333  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tows_df.to_csv(\"final_snowfall_and_tows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_declared</th>\n",
       "      <th>emergency</th>\n",
       "      <th>date_towed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2015-12-29</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Grant</th>\n",
       "      <th>2015-12-29</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-30</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-02-02</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Polk</th>\n",
       "      <th>2016-02-02</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-03</th>\n",
       "      <td>10.716147</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-04</th>\n",
       "      <td>10.728977</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-12-11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Dana</th>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>5.662611</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>6.622557</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>6.532358</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016-12-17</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ferry</th>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>4.498733</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>4.453197</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>4.274270</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-01-11</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Jane</th>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>4.012778</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>4.270025</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>4.161971</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-01-15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Olive</th>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>2.852083</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>2.916124</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>2.869013</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-01-22</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Pembina</th>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>0.051471</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>11.140431</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24</th>\n",
       "      <td>11.060855</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-02-23</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Xerxes</th>\n",
       "      <th>2018-02-23</th>\n",
       "      <td>5.188321</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24</th>\n",
       "      <td>5.159332</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-25</th>\n",
       "      <td>10.619750</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-02-25</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yardville</th>\n",
       "      <th>2018-02-25</th>\n",
       "      <td>6.095631</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>5.963526</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>6.103435</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2018-04-15</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Howe</th>\n",
       "      <th>2018-04-15</th>\n",
       "      <td>13.655338</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>15.110950</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>15.254636</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019-01-28</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Quincy</th>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>3.403548</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>3.458656</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-07</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Upton</th>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>4.318359</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>9.003516</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-09</th>\n",
       "      <td>8.910757</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-12</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Westminster</th>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>7.953986</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>8.369730</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>8.438369</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-20</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Yale</th>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>2.356579</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>7.415948</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>7.629290</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-02-24</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Armatage</th>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>3.674479</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>3.685707</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>3.788068</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2019-03-10</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Diamond Lake</th>\n",
       "      <th>2019-03-10</th>\n",
       "      <td>5.466254</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>5.385932</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>5.327416</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            mean  count\n",
       "date_declared emergency    date_towed                  \n",
       "2015-12-29    Grant        2015-12-29  -2.000000    171\n",
       "                           2015-12-30  -3.000000    912\n",
       "                           2015-12-31  -4.000000    473\n",
       "2016-02-02    Polk         2016-02-02   0.000000    149\n",
       "                           2016-02-03  10.716147    770\n",
       "                           2016-02-04  10.728977    461\n",
       "2016-12-11    Dana         2016-12-11   5.662611    113\n",
       "                           2016-12-12   6.622557    771\n",
       "                           2016-12-13   6.532358    470\n",
       "2016-12-17    Ferry        2016-12-17   4.498733    125\n",
       "                           2016-12-18   4.453197    769\n",
       "                           2016-12-19   4.274270    434\n",
       "2017-01-11    Jane         2017-01-11   4.012778     90\n",
       "                           2017-01-12   4.270025    804\n",
       "                           2017-01-13   4.161971    536\n",
       "2018-01-15    Olive        2018-01-15   2.852083    104\n",
       "                           2018-01-16   2.916124    645\n",
       "                           2018-01-17   2.869013    412\n",
       "2018-01-22    Pembina      2018-01-22   0.051471     68\n",
       "                           2018-01-23  11.140431    580\n",
       "                           2018-01-24  11.060855    314\n",
       "2018-02-23    Xerxes       2018-02-23   5.188321    132\n",
       "                           2018-02-24   5.159332    709\n",
       "                           2018-02-25  10.619750    374\n",
       "2018-02-25    Yardville    2018-02-25   6.095631    103\n",
       "                           2018-02-26   5.963526    510\n",
       "                           2018-02-27   6.103435    115\n",
       "2018-04-15    Howe         2018-04-15  13.655338     79\n",
       "                           2018-04-16  15.110950    486\n",
       "                           2018-04-17  15.254636    279\n",
       "2019-01-28    Quincy       2019-01-28   3.403548    101\n",
       "                           2019-01-29   3.458656    516\n",
       "2019-02-07    Upton        2019-02-07   4.318359     64\n",
       "                           2019-02-08   9.003516    446\n",
       "                           2019-02-09   8.910757    295\n",
       "2019-02-12    Westminster  2019-02-12   7.953986     92\n",
       "                           2019-02-13   8.369730    606\n",
       "                           2019-02-14   8.438369    282\n",
       "2019-02-20    Yale         2019-02-20   2.356579     76\n",
       "                           2019-02-21   7.415948    515\n",
       "                           2019-02-22   7.629290    303\n",
       "2019-02-24    Armatage     2019-02-24   3.674479     80\n",
       "                           2019-02-25   3.685707    535\n",
       "                           2019-02-26   3.788068    333\n",
       "2019-03-10    Diamond Lake 2019-03-10   5.466254    105\n",
       "                           2019-03-11   5.385932    488\n",
       "                           2019-03-12   5.327416    389"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_snowfall = expanded_tows_df.groupby(['date_declared', 'emergency', 'date_towed'])['Snowfall']\n",
    "grouped_snowfall.agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Armatage', 'Dana', 'Diamond Lake', 'Ferry', 'Howe', 'Jane',\n",
       "       'Olive', 'Pembina', 'Quincy', 'Upton', 'Westminster', 'Xerxes',\n",
       "       'Yale', 'Yardville', 'Grant', 'Polk'], dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tows_df['emergency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_tows_df = pd.read_csv('final_snowfall_and_tows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emergency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Armatage</th>\n",
       "      <td>3.720716</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dana</th>\n",
       "      <td>6.511134</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diamond Lake</th>\n",
       "      <td>5.371341</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ferry</th>\n",
       "      <td>4.399009</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grant</th>\n",
       "      <td>-3.194087</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Howe</th>\n",
       "      <td>15.022200</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane</th>\n",
       "      <td>4.213333</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olive</th>\n",
       "      <td>2.893669</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pembina</th>\n",
       "      <td>10.330622</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polk</th>\n",
       "      <td>9.563400</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quincy</th>\n",
       "      <td>3.449635</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upton</th>\n",
       "      <td>8.597039</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westminster</th>\n",
       "      <td>8.350452</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xerxes</th>\n",
       "      <td>6.843302</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yale</th>\n",
       "      <td>7.058152</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yardville</th>\n",
       "      <td>6.004318</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean  count\n",
       "emergency                     \n",
       "Armatage       3.720716    948\n",
       "Dana           6.511134   1354\n",
       "Diamond Lake   5.371341    982\n",
       "Ferry          4.399009   1328\n",
       "Grant         -3.194087   1556\n",
       "Howe          15.022200    844\n",
       "Jane           4.213333   1430\n",
       "Olive          2.893669   1161\n",
       "Pembina       10.330622    962\n",
       "Polk           9.563400   1380\n",
       "Quincy         3.449635    617\n",
       "Upton          8.597039    805\n",
       "Westminster    8.350452    980\n",
       "Xerxes         6.843302   1215\n",
       "Yale           7.058152    894\n",
       "Yardville      6.004318    728"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_snowfall = expanded_tows_df.groupby(['emergency'])['Snowfall']\n",
    "grouped_snowfall.agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_snowfall = expanded_tows_df.groupby(['date_declared', 'emergency'])['Snowfall']\n",
    "summary_result = grouped_snowfall.agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23306ae0940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(summary_result['mean'], summary_result['count'], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowfall amount doesn't play a role?\n",
    "# I need to look at how snowfall amounts are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_snowfall_and_tows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tows_df = df.groupby(['emergency'])['emergency'].agg('count')\n",
    "snow_df = df.groupby(['emergency'])['Snowfall'].agg('mean')\n",
    "date_df = df.groupby(['emergency'])['date_declared'].agg('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Armatage',\n",
       " 'Dana',\n",
       " 'Diamond Lake',\n",
       " 'Ferry',\n",
       " 'Grant',\n",
       " 'Howe',\n",
       " 'Jane',\n",
       " 'Olive',\n",
       " 'Pembina',\n",
       " 'Polk',\n",
       " 'Quincy',\n",
       " 'Upton',\n",
       " 'Westminster',\n",
       " 'Xerxes',\n",
       " 'Yale',\n",
       " 'Yardville']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[948,\n",
       " 1354,\n",
       " 982,\n",
       " 1328,\n",
       " 1556,\n",
       " 844,\n",
       " 1430,\n",
       " 1161,\n",
       " 962,\n",
       " 1380,\n",
       " 617,\n",
       " 805,\n",
       " 980,\n",
       " 1215,\n",
       " 894,\n",
       " 728]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emergency\n",
       "Armatage         948\n",
       "Dana            1354\n",
       "Diamond Lake     982\n",
       "Ferry           1328\n",
       "Grant           1556\n",
       "Howe             844\n",
       "Jane            1430\n",
       "Olive           1161\n",
       "Pembina          962\n",
       "Polk            1380\n",
       "Quincy           617\n",
       "Upton            805\n",
       "Westminster      980\n",
       "Xerxes          1215\n",
       "Yale             894\n",
       "Yardville        728\n",
       "Name: emergency, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
